# í”„ë¡¬í”„íŠ¸ ëª¨ìŒ ìƒì„±ê¸° (Python)

ì´ ì €ì¥ì†ŒëŠ” ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì •ë¦¬Â·í™•ì¥í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ Python ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê¸°ë³¸ ê¸ì •/ë¶€ì • í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ìƒì„±í•˜ê³ , ì›í•˜ë©´ ë¡œì»¬ LLM(Ollama)ì„ í†µí•´ ìœ ì‚¬í•œ ê¸ì • í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë„êµ¬ë³„ ì£¼ìš” ê¸°ëŠ¥

### generate_prompts
- ë””ë ‰í† ë¦¬/íŒŒì¼ ìŠ¤ìºí´ë”©: `output/positive.txt`, `output/negative.txt` ìƒì„±
- ê¸ì • í”„ë¡¬í”„íŠ¸: ë¼ì¸ë‹¹ 1ê°œ í”„ë¡¬í”„íŠ¸ ì €ì¥(ì™€ì¼ë“œì¹´ë“œ ì¹œí™”)
- LLM í†µí•©: Ollamaë¡œ ìœ ì‚¬ ê¸ì • í”„ë¡¬í”„íŠ¸ ë³€í˜• ìƒì„±(variants)
- Qwen-Image ëª¨ë“œ: ê°€ì´ë“œ í…œí”Œë¦¿(sentence/structured/tags) ì¶œë ¥ ì§€ì›
- ì•ˆì „ ê¸°ë³¸ê°’: ëª¨í˜¸í•œ ì—°ë ¹ í‘œí˜„ì„ ì„±ì¸ í‘œí˜„ìœ¼ë¡œ ì¹˜í™˜(ì˜µì…˜ í•´ì œ ê°€ëŠ¥)
- ì œì–´: ì œì™¸ í† í°(drop/reject), ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼/í”„ë¦¬ì…‹, ChatML í´ë°± ë“±

### scenario_prompt_maker
- ì‹œë‚˜ë¦¬ì˜¤ ì…ë ¥ â†’ ì»·(ìƒ·) í”„ë¦¬ì…‹ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
- Quality ë²ˆë“¤(ì˜ìƒ/ì¸ë¬¼) ë° ì‚¬ìš©ì ì •ì˜ í† í° ì¶”ê°€
- í† í”½ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ìë™ ìƒì„±(`--auto-scenario`)
- ì‹œí€€ìŠ¤ ëª¨ë“œ: ì»· ìˆ˜/ê¸¸ì´ì— ë§ëŠ” ìƒ·ë¦¬ìŠ¤íŠ¸ ìë™ ì„¤ê³„(`--sequence-auto`)
- ì•ˆì „í•œ í´ë”ëª…: ìŠ¬ëŸ¬ê·¸ ê¸¸ì´ ì œí•œ + í•´ì‹œ ì ‘ë¯¸ì‚¬
- ì‚°ì¶œë¬¼ ì¸ë±ìŠ¤: `INDEX.txt`ì— ì‹œë‚˜ë¦¬ì˜¤/ì„¤ì •/íŒŒì¼ ëª©ë¡ ê¸°ë¡

## ìš”êµ¬ ì‚¬í•­
- Python 3.8+
- LLM ìƒì„±ì„ ì‚¬ìš©í•˜ë ¤ë©´ Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ì¤€ë¹„

### GPU ê°€ì† ê´€ë ¨(Windows/Linux)
- ë³¸ ë„êµ¬ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ê°€ Ollama APIë¥¼ í˜¸ì¶œí•˜ëŠ” êµ¬ì¡°ë¡œ, ê°€ì†ì€ Ollamaê°€ ë‹´ë‹¹í•©ë‹ˆë‹¤.
- NVIDIA GPU ì‚¬ìš© ì‹œ ê¶Œì¥ ì‚¬í•­
  - ìµœì‹  NVIDIA ê·¸ë˜í”½ ë“œë¼ì´ë²„ ì„¤ì¹˜ í›„ `nvidia-smi`ê°€ ì •ìƒ ë™ì‘í•´ì•¼ í•©ë‹ˆë‹¤.
  - OllamaëŠ” ê¸°ë³¸ì ìœ¼ë¡œ GPUë¥¼ ìë™ ì‚¬ìš©í•©ë‹ˆë‹¤(CUDA Toolkit ë³„ë„ ì„¤ì¹˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í•„ìš” ì—†ìŒ).
  - VRAM ê°€ì´ë“œ(ëŒ€ëµ):
    - 7â€“8B(q5 ê³„ì—´): 6â€“8GB VRAM ê¶Œì¥
    - 14B(q4 ê³„ì—´): 12â€“16GB VRAM ê¶Œì¥
    - 30B(q4 ê³„ì—´): 24â€“32GB VRAM ê¶Œì¥
  - GPUê°€ ì¸ì‹ë˜ì§€ ì•Šì„ ë•Œ CPUë¡œ ê°•ì œ ì „í™˜: `OLLAMA_NO_GPU=1` í™˜ê²½ë³€ìˆ˜ ì„¤ì •
- AMD GPU(Linux, ROCm): ë°°í¬íŒ/ë“œë¼ì´ë²„ í™˜ê²½ì— ë”°ë¼ ì§€ì›ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì‹¤í—˜ì ). `rocminfo`ë¡œ í™•ì¸í•˜ì„¸ìš”.

## ìš´ì˜ì²´ì œë³„ ì‹¤í–‰ í™˜ê²½
ì•„ë˜ëŠ” Pythonê³¼ Ollama(ì„ íƒ)ì˜ ì„¤ì¹˜ ë° í™•ì¸ ë°©ë²•ì…ë‹ˆë‹¤.

### Ubuntu (Linux)
- Python ì„¤ì¹˜(ê¶Œì¥):
```bash
sudo apt update
sudo apt install -y python3 python3-venv python3-pip
```
- Ollama ì„¤ì¹˜(ì„ íƒ, LLM ì‚¬ìš© ì‹œ):
```bash
curl -fsSL https://ollama.com/install.sh | sh
# ì„œë¹„ìŠ¤ í™•ì¸
ollama --version && ollama list
```
- NVIDIA GPU ë“œë¼ì´ë²„(ì„ íƒ, ê°€ì† ì‹œ ê¶Œì¥):
```bash
sudo ubuntu-drivers autoinstall
sudo reboot
# ì¬ë¶€íŒ… í›„
nvidia-smi
```
- ëª¨ë¸ ì¤€ë¹„(ì˜ˆ):
```bash
ollama pull qwen2.5:7b-instruct-q5_K_M
# ë™ì‘ í™•ì¸
ollama run qwen2.5:7b-instruct-q5_K_M "hello"
```
- ì‹¤í–‰:
```bash
python3 scripts/generate_prompts.py --skip-base --llm \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --seed "cat eye shape, almond eyes, sharp eyeliner, ..." \
  --variants 5 --append
```

### macOS (Apple Silicon í¬í•¨)
- Python: ê¸°ë³¸ ë‚´ì¥ë˜ì§€ë§Œ ìµœì‹  ë²„ì „ì„ ê¶Œì¥í•©ë‹ˆë‹¤(Homebrew ì˜ˆì‹œ).
```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
brew install python@3
```
- Ollama(ì„ íƒ):
```bash
brew install ollama
ollama --version && ollama list
```
- ëª¨ë¸ ì¤€ë¹„(ì˜ˆ):
```bash
ollama pull llama3.1:8b-instruct-q5_K_M
ollama pull qwen2.5:7b-instruct-q5_K_M
```
- ì‹¤í–‰(ë©€í‹°ë¼ì¸ ì˜ˆì‹œ):
```bash
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --from-file output/positive.txt \
  --variants 3 \
  --append
```

### Windows 11/10
- Python ì„¤ì¹˜: https://www.python.org/downloads/ ì—ì„œ ì„¤ì¹˜(ë˜ëŠ” Microsoft Store).
  - PowerShellì—ì„œ ë²„ì „ í™•ì¸: `python --version` ë˜ëŠ” `py -3 --version`
- Ollama(ì„ íƒ): Windowsìš© ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ì‚¬ìš©(https://ollama.com/). ì„¤ì¹˜ í›„ PowerShellì—ì„œ:
```powershell
ollama --version; ollama list
ollama pull qwen2.5:7b-instruct-q5_K_M
```
- NVIDIA GPU ê°€ì†(ì„ íƒ): ìµœì‹  NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ í›„ ì‹œìŠ¤í…œ ì¬ë¶€íŒ… â†’ PowerShellì—ì„œ ë‹¤ìŒ ì‹¤í–‰
```powershell
nvidia-smi
```
- GPU ìë™ ì‚¬ìš©ì´ ì–´ë ¤ìš°ë©´ CPU ê°•ì œ ì „í™˜(ì¼ì‹œ):
```powershell
$env:OLLAMA_NO_GPU = "1"; ollama run qwen2.5:7b-instruct-q5_K_M "hello"
```
- ì‹¤í–‰:
  - í•œ ì¤„ ì‹¤í–‰(ê¶Œì¥):
```powershell
python scripts/generate_prompts.py --skip-base --llm --model "qwen2.5:7b-instruct-q5_K_M" --variants 3 --append
```
  - PowerShell ë©€í‹°ë¼ì¸ì€ ë°±í‹±(`) ì‚¬ìš©:
```powershell
python scripts/generate_prompts.py `
  --skip-base --llm `
  --model "qwen2.5:7b-instruct-q5_K_M" `
  --variants 3 `
  --append
```
  - CMD.exeì—ì„œëŠ” ìºëŸ¿(^) ì‚¬ìš©:
```cmd
python scripts\generate_prompts.py ^
  --skip-base --llm ^
  --model "qwen2.5:7b-instruct-q5_K_M" ^
  --variants 3 ^
  --append
```

## generate_prompts ì‚¬ìš©ë²•

## ë¹ ë¥¸ ì‹œì‘
```bash
# ê¸°ë³¸ ê¸ì •/ë¶€ì • í”„ë¡¬í”„íŠ¸ íŒŒì¼ ìƒì„±
python3 scripts/generate_prompts.py

# ê²°ê³¼
# - output/positive.txt: ìƒ˜í”Œ ê¸ì • í”„ë¡¬í”„íŠ¸ 1ì¤„
# - output/negative.txt: ìƒ˜í”Œ ë¶€ì • í”„ë¡¬í”„íŠ¸ 1ì¤„
```

ìƒì„±ëœ ê¸ì • í”„ë¡¬í”„íŠ¸ëŠ” ë¼ì¸ë‹¹ 1ê°œì˜ ì½¤ë§ˆ êµ¬ë¶„ í† í° ëª©ë¡ìœ¼ë¡œ êµ¬ì„±ë˜ì–´, ì™€ì¼ë“œì¹´ë“œ í™•ì¥ì— ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## LLMìœ¼ë¡œ ìœ ì‚¬ í”„ë¡¬í”„íŠ¸ ìƒì„± (Ollama)
1) Ollama ì„¤ì¹˜(íƒ1)
- í™ˆí˜ì´ì§€ì—ì„œ ì„¤ì¹˜ íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ í›„ ì„¤ì¹˜(ë§¥OS ê¶Œì¥)
- ë˜ëŠ” Homebrew: `brew install ollama`

2) ëª¨ë¸ ì¤€ë¹„(ì˜ˆì‹œ)
```bash
# ê¶Œì¥ ì˜ˆì‹œ ëª¨ë¸(ì†ë„/í’ˆì§ˆ ë°¸ëŸ°ìŠ¤)
ollama pull llama3.1:8b-instruct-q5_K_M
ollama pull qwen2.5:7b-instruct-q5_K_M
```

3) ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ
```bash
# ê¸°ì¡´ positive.txtì— ìœ ì‚¬ í”„ë¡¬í”„íŠ¸ 5ì¤„ ì¶”ê°€
python3 scripts/generate_prompts.py --skip-base --llm --variants 5 --append

# íŠ¹ì • ëª¨ë¸ê³¼ ì‹œë“œë¥¼ ì§ì ‘ ì§€ì •
python3 scripts/generate_prompts.py \
  --llm \
  --model "llama3.1:8b-instruct-q5_K_M" \
  --seed "cat eye shape, almond eyes, sharp eyeliner, ..." \
  --variants 3 \
  --append

# íŒŒì¼ì—ì„œ ì—¬ëŸ¬ ì‹œë“œë¥¼ ì½ì–´ ê°ê° ë³€í˜• ìƒì„±
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --from-file output/positive.txt \
  --variants 3 \
  --append
```

ê¸°ë³¸ LLM í˜¸ìŠ¤íŠ¸ëŠ” `http://localhost:11434` ì´ë©°, Ollamaê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

### CLI ì˜µì…˜ ìš”ì•½ (generate_prompts)
```text
--out-dir <PATH>            ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: output)
--append                    ê¸°ì¡´ íŒŒì¼ì— ì´ì–´ì“°ê¸°
--llm                       LLMì„ ì‚¬ìš©í•´ ìœ ì‚¬ ê¸ì • í”„ë¡¬í”„íŠ¸ ìƒì„±
--model <NAME>              Ollama ëª¨ë¸ëª… (ê¸°ë³¸: llama3.1:8b-instruct-q5_K_M)
--llm-host <URL>            Ollama í˜¸ìŠ¤íŠ¸ URL (ê¸°ë³¸: http://localhost:11434)
--variants <N>              ì‹œë“œë‹¹ ìƒì„±í•  ë³€í˜• ê°œìˆ˜ (ê¸°ë³¸: 3)
--temperature <F>           ìƒ˜í”Œë§ ì˜¨ë„ (ê¸°ë³¸: 0.7)
--seed <TEXT>               ë‹¨ì¼ ì‹œë“œ ë¬¸ìì—´ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
--from-file <FILE>          ì‹œë“œ ëª©ë¡ íŒŒì¼(ë¼ì¸ë‹¹ 1ê°œ)
--llm-mode <generate|chat>  Ollama API ëª¨ë“œ ì„ íƒ (ê¸°ë³¸: generate)
--debug-llm                 ì›ë³¸/ì •ê·œí™” ì¶œë ¥ ë””ë²„ê·¸ ë¡œê·¸
--skip-base                 ê¸°ë³¸ ìƒ˜í”Œ íŒŒì¼ ì“°ê¸° ìƒëµ
--variants-out <FILE>       ë³€í˜• ê²°ê³¼ë¥¼ ë³„ë„ íŒŒì¼ì— ê¸°ë¡
--incremental               ìƒì„± ì¦‰ì‹œ 1ë¼ì¸ì”© ê³§ë°”ë¡œ append
--fsync                     ê° ë¼ì¸ ì“°ê¸° í›„ fsync(ì•ˆì „, ëŠë¦¼)
--progress-every <N>        Në¼ì¸ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥(0=ë„ê¸°)
--system-prompt <TEXT>      chat/ChatMLì—ì„œ ì‚¬ìš©í•  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
--system-prompt-file <FILE> íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì½ê¸°(í…ìŠ¤íŠ¸ë³´ë‹¤ ìš°ì„ )
--system-prompt-preset <NAME>
                             ë‚´ì¥ í”„ë¦¬ì…‹ ì‚¬ìš©(í…ìŠ¤íŠ¸/íŒŒì¼ ë¯¸ì§€ì • ì‹œ ì ìš©)
--no-qwen-chatml-fallback   Qwenìš© ChatML í´ë°± ë¹„í™œì„±í™”
--qwen-image                 Qwen-Image ê³µì‹ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
--qwen-style <sentence|structured|tags>
                             ì¶œë ¥ í˜•ì‹ ì„ íƒ(ê¸°ë³¸: sentence)
--qwen-out <FILE>            Qwen-Image ê²°ê³¼ë¥¼ ë³„ë„ íŒŒì¼ì— ê¸°ë¡
--exclude <TOKENS>          ì œì™¸ í† í°(ì½¤ë§ˆ êµ¬ë¶„), ë°˜ë³µ ì§€ì • ê°€ëŠ¥
--exclude-file <FILE>       ì œì™¸ í† í° íŒŒì¼(ë¼ì¸ ë˜ëŠ” ì½¤ë§ˆ êµ¬ë¶„)
--exclude-mode <drop|reject>ì œì™¸ ë°©ì‹: drop=í† í°ë§Œ ì œê±°, reject=ë¼ì¸ íê¸°
--retries <N>               reject ëª¨ë“œì—ì„œ ê° ë¼ì¸ ì¬ì‹œë„ íšŸìˆ˜(ê¸°ë³¸ 3)
--no-safe-adult-tags        ëª¨í˜¸í•œ ì—°ë ¹ í‘œí˜„ ì¹˜í™˜ ë¹„í™œì„±í™”
```

 

## ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë¶€í„° ìƒì„±
- ë³´ìœ  ì¤‘ì¸ í…ìŠ¤íŠ¸ íŒŒì¼(ë¼ì¸ë‹¹ 1ê°œ ì‹œë“œ í”„ë¡¬í”„íŠ¸)ì„ ê·¸ëŒ€ë¡œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê° ë¼ì¸ì€ â€œì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ê¸ì • íƒœê·¸â€ í˜•ì‹ì´ ê¶Œì¥ë©ë‹ˆë‹¤.

ì˜ˆì‹œ:
```bash
# my_seeds.txt(ë¼ì¸ë‹¹ 1ê°œ)ë¡œë¶€í„° ì‹œë“œ ì½ê³ , ë³€í˜•ì„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --from-file my_seeds.txt \
  --variants 5 \
  --variants-out output/variants.txt \
  --incremental --progress-every 50 --append
```

### ì œì™¸ í‚¤ì›Œë“œ í™œìš©
ì›ì¹˜ ì•ŠëŠ” íƒœê·¸ê°€ í¬í•¨ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ë ¤ë©´ ì œì™¸ í† í°ì„ ì§€ì •í•˜ì„¸ìš”.

```bash
# 1) í† í°ë§Œ ì œê±°(drop)
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --from-file my_seeds.txt \
  --exclude "animal ears, hat" \
  --exclude-file exclude.txt \
  --exclude-mode drop \
  --variants 10 --variants-out output/variants.txt --incremental --append

# 2) í•´ë‹¹ í† í°ì´ í¬í•¨ëœ ë¼ì¸ì„ ì•„ì˜ˆ ë²„ë¦¬ê³  ì¬ì‹œë„(reject)
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --seed "cat eye shape, almond eyes, sharp eyeliner, ..." \
  --exclude "hat" \
  --exclude-mode reject --retries 5 \
  --variants 100 --incremental --progress-every 10 --append
```
í† í° ë§¤ì¹­ì€ ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ê´„í˜¸/ê°€ì¤‘ì¹˜ ì œê±° ë’¤ ë¹„êµí•©ë‹ˆë‹¤. ì˜ˆ) `((hat))`ë„ `hat`ê³¼ ì¼ì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

### ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ íŒŒì¼ë¡œ ì§€ì •
ê¸´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” íŒŒì¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ í¸ë¦¬í•©ë‹ˆë‹¤. `--system-prompt-file`ì´ ì§€ì •ë˜ë©´ `--system-prompt`ë³´ë‹¤ ìš°ì„ í•©ë‹ˆë‹¤.

```bash
# ì˜ˆ: system_prompt.txt íŒŒì¼ì„ ì‚¬ìš©
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --from-file my_seeds.txt \
  --system-prompt-file system_prompt.txt \
  --variants 20 --incremental --progress-every 10 --append
```

### ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹
íŒŒì¼/í…ìŠ¤íŠ¸ ëŒ€ì‹  ë‚´ì¥ í”„ë¦¬ì…‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì§€ì›: `illustrious-xl`.

```bash
# Illustrious-XL í”„ë¦¬ì…‹(íƒœê·¸í˜• ë³€í˜• ìƒì„±)
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --from-file my_seeds.txt \
  --system-prompt-preset illustrious-xl \
  --variants 10 --variants-out output/variants.txt --append

# Illustrious-XL í”„ë¦¬ì…‹(Qwen-Image ëª¨ë“œ)
python3 scripts/generate_prompts.py \
  --skip-base --llm --qwen-image \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --from-file my_seeds.txt \
  --qwen-style sentence \
  --system-prompt-preset illustrious-xl \
  --variants 5 --qwen-out output/qwen_image_prompts.txt --append
```
ìš°ì„ ìˆœìœ„: `--system-prompt-file` > `--system-prompt` > `--system-prompt-preset` > ë‚´ì¥ ê¸°ë³¸ê°’

## ì‹œë‚˜ë¦¬ì˜¤ í”„ë¡¬í”„íŠ¸ ì œì‘ê¸°(ì»·/ìƒ·)
`scripts/scenario_prompt_maker.py`ëŠ” â€œìƒí™©/ì´ì•¼ê¸°(Scenario)â€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ìŠ¤í† ë¦¬ë³´ë“œ ì»·(ìƒ·) í”„ë¦¬ì…‹ì— ë”°ë¼ Qwen-Image ê°€ì´ë“œ í˜•ì‹ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì˜µì…˜ìœ¼ë¡œ Quality(ì´ë¯¸ì§€ í’ˆì§ˆ ì§€í–¥) ì˜ìƒ/ì¸ë¬¼ í‚¤ì›Œë“œ ë²ˆë“¤ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜: `--scenario` ë˜ëŠ” `--scenario-file`
- ì»· í”„ë¦¬ì…‹: `--preset storyboard`(ê¸°ë³¸) â€“ Establishing, Wide, Medium, Close-up, Over-Shoulder, Detail
- ìŠ¤íƒ€ì¼: `--style sentence|structured|tags` (Qwen-Image ê°€ì´ë“œ)
- ë²ˆë“¤(ì„ íƒ): `--bundle quality-outfit`, `--bundle quality-character` (ì¶”ê°€ í† í°ì€ `--extra-bundle`)
 - ë²ˆë“¤(ì„ íƒ): `--bundle quality-outfit`, `--bundle quality-character`, `--bundle nsfw-soft`, `--bundle nsfw-boudoir` (ì¶”ê°€ í† í°ì€ `--extra-bundle`)
- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ê¸°ë³¸ê°’ìœ¼ë¡œ `QWEN Image Creation Prompt Engineer Guide.txt`ë¥¼ ì‚¬ìš©
- ê²°ê³¼: `output/scenarios/<slug>/<NN>_<shot>.txt` íŒŒì¼ë“¤ë¡œ ì €ì¥

### ì‹œí€€ìŠ¤ ëª¨ë“œ(10ì´ˆ ì˜ìƒ ì»· í”Œë˜ë‹)
- ì»· ìˆ˜ ì§€ì •: `--num-cuts 3`(ìµœì†Œ) ~ `--num-cuts 10`(ê¶Œì¥)
- ê¸¸ì´ ëª©í‘œ: `--duration-sec 10`(ê¸°ë³¸)
- ìë™ ìƒ·ë¦¬ìŠ¤íŠ¸ ìƒì„±: `--sequence-auto` ì‚¬ìš© ì‹œ, ì‹œë‚˜ë¦¬ì˜¤/í† í”½ì„ ë°”íƒ•ìœ¼ë¡œ ì¼ê´€ëœ ì‹œí€€ìŠ¤(ì—°ì†ì„±, ì¹´ë©”ë¼ ì›€ì§ì„, ì•µê¸€)ë¥¼ LLMì´ ì„¤ê³„í•˜ê³ , ì»·ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- í† í”½ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ë„ í•¨ê»˜ ìë™ ìƒì„±í•˜ë ¤ë©´ `--topic ... --auto-scenario`ë¥¼ ë³‘í–‰í•˜ì„¸ìš”.

ì˜ˆì‹œ(ì˜ë¬¸ ì‹œë‚˜ë¦¬ì˜¤ ìë™ ìƒì„± + 5ì»· ì‹œí€€ìŠ¤ + íƒœê·¸í˜• ì¶œë ¥):
```bash
python3 scripts/scenario_prompt_maker.py \
  --topic "proposal in a fancy restaurant" --topic "rainstorm" \
  --auto-scenario --story-language en --story-sentences 3 \
  --sequence-auto --num-cuts 5 --duration-sec 10 \
  --style tags --variants 1
```

ì˜ˆì‹œ(íƒœê·¸í˜•, ë²ˆë“¤ 2ì¢…, ì»·ë³„ 3ë³€í˜•):
```bash
python3 scripts/scenario_prompt_maker.py \
  --scenario "Rainy neon alley; a poised woman exits a jazz bar" \
  --bundle quality-outfit --bundle quality-character \
  --style tags --variants 3 \
  --model "qwen2.5:7b-instruct-q5_K_M"
```

ì˜ˆì‹œ(ë¼ë²¨í˜•, ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê¸°ë³¸ê°’ ì‚¬ìš©):
```bash
python3 scripts/scenario_prompt_maker.py \
  --scenario "Dawn on a foggy harbor, minimal elegance" \
  --style structured --variants 2
```

ì¶œë ¥ êµ¬ì¡° ì˜ˆì‹œ:
```text
output/scenarios/
  rainy-neon-alley-a-poised-woman-exits-a-jazz-bar/
    01_establishing.txt
    02_wide.txt
    03_medium.txt
    04_closeup.txt
    05_over_shoulder.txt
    06_detail.txt
    INDEX.txt
```

íŒ
- ì‹œë‚˜ë¦¬ì˜¤ëŠ” í•œêµ­ì–´ì—¬ë„ ë¬´ë°©í•˜ë‚˜, ì‹œìŠ¤í…œ ê·œì¹™ìƒ ì¶œë ¥ì€ ì˜ì–´ë¡œ 1ì¤„ í˜•ì‹ì„ ì—„ê²©íˆ ë”°ë¦…ë‹ˆë‹¤.
- `--extra-bundle "comma, separated, tokens"`ë¡œ ììœ  í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### CLI ì˜µì…˜ ìš”ì•½ (scenario_prompt_maker)
```text
--scenario <TEXT>                    ì‹œë‚˜ë¦¬ì˜¤(ì§§ì€ ë¬¸ì¥). íŒŒì¼ ì…ë ¥ì€ --scenario-file
--scenario-file <FILE>               ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ íŒŒì¼
--topic <TEXT>                       í† í”½/í‚¤ì›Œë“œ(ë°˜ë³µ ì§€ì •). íŒŒì¼ ì…ë ¥ì€ --topic-file
--topic-file <FILE>                  í† í”½ íŒŒì¼(ì½¤ë§ˆ/ê°œí–‰ êµ¬ë¶„)
--auto-scenario                      í† í”½ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ìë™ ìƒì„± í™œì„±í™”
--story-sentences <N>                ìë™ ì‹œë‚˜ë¦¬ì˜¤ ë¬¸ì¥ ìˆ˜(ê¸°ë³¸ 2)
--story-language <en|ko>             ìë™ ì‹œë‚˜ë¦¬ì˜¤ ì–¸ì–´(ê¸°ë³¸ ko)
--story-style <logline|vignette>     ìë™ ì‹œë‚˜ë¦¬ì˜¤ ìŠ¤íƒ€ì¼(ê¸°ë³¸ logline)

--preset <NAME>                      ì»· í”„ë¦¬ì…‹(ê¸°ë³¸ storyboard)
--num-cuts <N>                       ì»· ìˆ˜ ì§€ì •(ì˜ˆ: 3â€“10)
--duration-sec <N>                   ì „ì²´ ê¸¸ì´ ëª©í‘œ(ì´ˆ, ê¸°ë³¸ 10)
--sequence-auto                      ì‹œë‚˜ë¦¬ì˜¤ë¡œë¶€í„° ìƒ·ë¦¬ìŠ¤íŠ¸ ìë™ ì„¤ê³„

--bundle <quality-outfit|quality-character|nsfw-soft|nsfw-boudoir>
                                     í’ˆì§ˆ/NSFW(ë¹„ë…¸ê³¨ì ) ë²ˆë“¤(ë°˜ë³µ ê°€ëŠ¥)
--extra-bundle <TOKENS>              ì¶”ê°€ í† í°(ì½¤ë§ˆ êµ¬ë¶„, ë°˜ë³µ ê°€ëŠ¥)

--style <sentence|structured|tags>   Qwen-Image ì¶œë ¥ í˜•ì‹(ê¸°ë³¸ sentence)
--variants <N>                       ì»·ë³„ ë³€í˜• ê°œìˆ˜(ê¸°ë³¸ 3)
--temperature <F>                    ìƒ˜í”Œë§ ì˜¨ë„(ê¸°ë³¸ 0.7)
--model <NAME>                       Ollama ëª¨ë¸ëª…(ê¸°ë³¸ qwen2.5:7b-instruct-q5_K_M)
--llm-host <URL>                     Ollama í˜¸ìŠ¤íŠ¸(ê¸°ë³¸ http://localhost:11434)
--llm-mode <generate|chat>           API ëª¨ë“œ(ê¸°ë³¸ generate, --chat ë³„ì¹­ ì§€ì›)
--system-prompt-file <FILE>          ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼(ê¸°ë³¸ QWEN ê°€ì´ë“œ íŒŒì¼)
--no-safe-adult-tags                 ëª¨í˜¸í•œ ì—°ë ¹ í‘œí˜„ ì¹˜í™˜ ë¹„í™œì„±í™”

--out-dir <DIR>                      ì¶œë ¥ ë² ì´ìŠ¤(ê¸°ë³¸ output/scenarios)
--slug-max-len <N>                   ì‹œë‚˜ë¦¬ì˜¤ í´ë” ìŠ¬ëŸ¬ê·¸ ìµœëŒ€ ê¸¸ì´(ê¸°ë³¸ 80, í•´ì‹œ ì ‘ë¯¸ì‚¬)
--name <TEXT>                        í´ë”ëª… ìŠ¬ëŸ¬ê·¸ì— ì“¸ í‘œì‹œ ì´ë¦„
--debug                              LLM ì›ë³¸/ì •ê·œí™” ì¶œë ¥ ë””ë²„ê·¸
 
ì„±ì¸ ì „ìš© ì˜µì…˜
--adult-only                         ì‹œë“œì— 'adult woman' íŒíŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì„±ì¸ë§Œ ëŒ€ìƒìœ¼ë¡œ ê°•ì œ
--adult-flag-filenames               ìƒì„± íŒŒì¼ëª…ì„ *_adult.txt í˜•íƒœë¡œ ì €ì¥í•˜ê³  INDEXì— í‘œì‹œ
--adult-reject-minor                 ë¯¸ì„±ë…„ ê´€ë ¨ ê¸ˆì¹™ì–´ í¬í•¨ ë¼ì¸ í•„í„°ë§(íŒŒì¼ ê¸°ë¡ ì•ˆ í•¨)
--adult-banned <TOKENS>              ê¸ˆì¹™ì–´ ì¶”ê°€(ë°˜ë³µ ê°€ëŠ¥, ì½¤ë§ˆ êµ¬ë¶„)
--adult-banned-file <FILE>           ê¸ˆì¹™ì–´ ì¶”ê°€ íŒŒì¼(ì½¤ë§ˆ/ê°œí–‰ êµ¬ë¶„)
```


### Qwen-Image í”„ë¡¬í”„íŠ¸ ìƒì„± ëª¨ë“œ (generate_prompts)
`--qwen-image`ë¥¼ ì‚¬ìš©í•˜ë©´ ì‹œë“œ í† í°(`--seed` / `--from-file`)ì„ ë°”íƒ•ìœ¼ë¡œ Qwen-Image ê°€ì´ë“œë¼ì¸ì— ë§ì¶˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

- ìŠ¤íƒ€ì¼ ì„ íƒ(`--qwen-style`):
  - `sentence`: 1ì¤„ ë‚´ 1â€“3ê°œ ì˜ì–´ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ê¸°ìˆ (ê¸°ë³¸)
  - `structured`: ë¼ë²¨ í¬í•¨(Subject; Scene; Style; Lens; Atmosphere; Detail) 1ì¤„ ì¶œë ¥
  - `tags`: í…œí”Œë¦¿ ìˆœì„œì˜ ì½¤ë§ˆ êµ¬ë¶„ ì¡°ê°ìœ¼ë¡œ 1ì¤„ ì¶œë ¥

ì˜ˆì‹œ(ë¬¸ì¥í˜•):
```bash
python3 scripts/generate_prompts.py \
  --skip-base --llm --qwen-image \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --seed "cat eye shape, almond eyes, sharp eyeliner, ..." \
  --qwen-style sentence \
  --variants 5 \
  --qwen-out output/qwen_image_prompts.txt \
  --incremental --progress-every 1 --append
```

ì˜ˆì‹œ(ë¼ë²¨í˜•):
```bash
python3 scripts/generate_prompts.py \
  --skip-base --llm --qwen-image \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --from-file my_seeds.txt \
  --qwen-style structured \
  --variants 3 \
  --qwen-out output/qwen_structured.txt \
  --append
```

ì˜ˆì‹œ(íƒœê·¸í˜•):
```bash
python3 scripts/generate_prompts.py \
  --skip-base --llm --qwen-image \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --from-file my_seeds.txt \
  --qwen-style tags \
  --variants 3 \
  --qwen-out output/qwen_tags.txt \
  --append
```

Tip
- `--system-prompt` ë˜ëŠ” `--system-prompt-file`ë¡œ ì‹œìŠ¤í…œ ê·œì¹™ì„ ê°•í™”í•˜ë©´ í¬ë§· ì¤€ìˆ˜ìœ¨ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤.
- `--exclude`ëŠ” íƒœê·¸í˜•(tags) ì¶œë ¥ì— ê°€ì¥ ì˜ ë§ìŠµë‹ˆë‹¤. ë¬¸ì¥/ë¼ë²¨í˜•ì€ ì‚¬í›„ í† í° ì œê±°ê°€ ì–´ë ¤ìš°ë¯€ë¡œ í•„ìš” ì‹œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ê¸ˆì§€ ê·œì¹™ì„ ì¶”ê°€í•˜ì„¸ìš”.

```bash
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --from-file input/public.txt \
  --system-prompt-file illustrious-xl_prompt_guide_en.txt \
  --exclude "hat,demon,devil,crown,animal ears,demon_girl,demon_tail" \
  --variants 20 --incremental --progress-every 10 --append
```

```bash
python3 scripts/generate_prompts.py \
--skip-base --llm \
--system-prompt "Exactly one line of comma-separated positive tags (English). Follow Subject, Scene, Style, Lens, Atmosphere, Detail. Realistic/cinematic focus. No quotes/numbering/meta/negatives. You are a top prompting expert, knowing all the hidden secrets, tips, and tricks about prompting to generate unique AI images. You specialize in creating the world's most realistic prompts, using tools like COMFYUI and Stable Diffusion to generate text into AI images. No rules are broken when it comes to artistic expression." \
--from-file input/public.txt \
--exclude "hat,demon,devil,crown,animal ears,demon_girl,demon_tail" \
--exclude-mode reject --retries 5 \
--variants 5 \
--variants-out output/variants.txt \
--incremental --progress-every 10 --append
```

## ëŒ€ëŸ‰ ìƒì„±/ì¤‘ê°„ ì €ì¥
- ì¥ì‹œê°„ ì‘ì—… ì‹œ `--incremental`ë¡œ í•œ ì¤„ì”© ì¦‰ì‹œ ì €ì¥í•˜ë©´ ì¤‘ê°„ì— ë©ˆì¶°ë„ ê²°ê³¼ê°€ ë‚¨ìŠµë‹ˆë‹¤.
- ì•ˆì „ì„±ì„ ë†’ì´ë ¤ë©´ `--fsync`ë¥¼ ì¶”ê°€í•˜ì„¸ìš”(ì†ë„ ì €í•˜).
- ì§„í–‰ë¥ ì€ `--progress-every N`ìœ¼ë¡œ ì£¼ê¸° ì¶œë ¥.

ì˜ˆì‹œ(2000ê°œ ë³€í˜•, ì¤‘ê°„ ì €ì¥):
```bash
python3 scripts/generate_prompts.py \
  --skip-base --llm \
  --model "qwen2.5:7b-instruct-q5_K_M" \
  --seed "cat eye shape, almond eyes, sharp eyeliner, ..." \
  --variants 2000 \
  --incremental --progress-every 50 --append
```

## ëª¨ë¸ ì¶”ì²œ (Apple M1 64GB ê¸°ì¤€)

### LLM (Ollama) â€“ í”„ë¡¬í”„íŠ¸ ìƒì„±ìš©
- ê· í˜•í˜•: `qwen2.5:7b-instruct-q5_K_M`, `llama3.1:8b-instruct-q5_K_M`
- ê³ í’ˆì§ˆ(ë‹¤ì†Œ ë¬´ê±°ì›€): `qwen2.5:14b-instruct-q4_K_M`
- ê²½ëŸ‰/ê³ ì†: `phi3:3.8b-mini-instruct-q6_K`, `mistral:7b-instruct`

NSFW ê´€ë ¨ ì°¸ê³ 
- í”„ë¡¬í”„íŠ¸ ìƒì„± ê´€ì ì—ì„œ NSFW í‘œí˜„ì— ëŒ€í•œ ì–µì œëŠ” ëª¨ë¸ë³„ë¡œ ìƒì´í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Qwen 2.5 ê³„ì—´ì´ Llama3.1ë³´ë‹¤ ì™„ê³¡í•˜ë©°, Mistral 7B Instructë„ ìƒëŒ€ì ìœ¼ë¡œ ê´€ëŒ€í•œ í¸ì…ë‹ˆë‹¤. ë‹¤ë§Œ ì–´ëŠ ê²½ìš°ë“  ë¯¸ì„±ë…„ ê´€ë ¨ ë‚´ìš©ì€ ì ˆëŒ€ ê¸ˆì§€í•˜ë©°, í˜„ì§€ ë²•ê³¼ í”Œë«í¼ ì •ì±…ì„ ì¤€ìˆ˜í•˜ì„¸ìš”.

### ì´ë¯¸ì§€ ëª¨ë¸ (ì™¸ë¶€ íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ)
- ë²”ìš©: Stable Diffusion XL 1.0(SDXL), Stable Diffusion 1.5 + ì»¤ìŠ¤í…€ ì²´í¬í¬ì¸íŠ¸/LoRA
- ë¦¬ì–¼ë¦¬ì¦˜ ê³„ì—´(ì˜ˆì‹œ): Realistic Vision, Deliberate
- ì• ë‹ˆ/ì¼ëŸ¬ìŠ¤íŠ¸ ê³„ì—´(ì˜ˆì‹œ): Anything v5, AbyssOrangeMix3

NSFW ê´€ë ¨ ì°¸ê³ 
- ìœ„ ì¼ë¶€ ì»¤ìŠ¤í…€ ì²´í¬í¬ì¸íŠ¸ëŠ” NSFW ìƒì„±ì— ê´€ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš© êµ­ê°€/ì„œë¹„ìŠ¤ì˜ ì •ì±…ì„ ì¤€ìˆ˜í•˜ê³ , ì„±ì¸ë§Œì„ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ìƒìœ¼ë¡œ í•˜ë©°, ì°©ì·¨ì /ë¶ˆë²• ì½˜í…ì¸ ëŠ” ì ˆëŒ€ ê¸ˆì§€í•˜ì„¸ìš”. ë³¸ ì €ì¥ì†ŒëŠ” ì‹œê°ì  ì„±ì¸/ë¯¸ì„±ë…„ ëª¨í˜¸ì„±ì„ ì¤„ì´ë„ë¡ ê¸°ë³¸ì ìœ¼ë¡œ ëª¨í˜¸í•œ íƒœê·¸ë¥¼ ì„±ì¸ í‘œí˜„ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.

> ì°¸ê³ : Qwen3 ê³„ì—´ì€ Ollama íŒ¨í‚¤ì§•/í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ì œê°ê°ì´ë¼ í•œ ì¤„ ì¶œë ¥ ì¤€ìˆ˜ì„±ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ë„êµ¬ëŠ” â€œì •í™•íˆ 1ì¤„â€ ì¶œë ¥ì„ ê¸°ëŒ€í•˜ë¯€ë¡œ, ìš°ì„  Llama3.1 Â· Qwen2.5ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.

---

## ğŸ’» ë¡œì»¬ ì‹¤í–‰ ê°€ëŠ¥í•œ Roleplay / NSFW LLM ëª©ë¡

| êµ¬ë¶„ | ëª¨ë¸ëª…                                               | íŒŒë¼ë¯¸í„°             | ì£¼ìš” íŠ¹ì§•                                                |
| -- | ------------------------------------------------- | ---------------- | ---------------------------------------------------- |
| 1  | **Blue-Orchid-2x7B**                              | 2Ã—7B (MoE)       | Explicit RPìš© MoE ëª¨ë¸ (Dialogue + Storywriting ì „ë¬¸ê°€ ë¶„ë¦¬) |
| 2  | **Mistral 22B**                                   | 22B              | ê²€ì—´ ì ìŒ, ìºë¦­í„° ì¼ê´€ì„± ë³´í†µ, í° VRAM ìš”êµ¬                         |
| 3  | **L3.1 Euryale 2.2**                              | 70B+             | ê³ í’ˆì§ˆ Roleplay, ëŒ€í˜• ì„œë²„ê¸‰ VRAM í•„ìš”                         |
| 4  | **Midnight Miqu 103B**                            | 103B             | ëª°ì…ê° ê°•í•¨, 64GB ì´ìƒ RAM ê¶Œì¥                               |
| 5  | **Magnum 123B / 70B**                             | 70~123B          | ëŒ€í˜• ê³ í’ˆì§ˆ NSFW ëª¨ë¸                                       |
| 6  | **Luminum 123B**                                  | 123B             | Magnum ê³„ì—´, ì°½ì˜ì  RPì— ê°•í•¨                                |
| 7  | **Wizard2 8Ã—22B**                                 | 176B (8Ã—22B MoE) | ê±°ëŒ€ MoE êµ¬ì¡°, ê³ ì„±ëŠ¥                                       |
| 8  | **Stheno 3.2**                                    | 13B ì •ë„           | RTX 3070ê¸‰ì—ì„œë„ êµ¬ë™ ê°€ëŠ¥                                   |
| 9  | **Gemmasutra**                                    | ì•½ 13B            | ì–¸ì„¼ì„œë“œ, ê°ì • í‘œí˜„ ìš°ìˆ˜                                       |
| 10 | **Dirty-Muse-Writer-v01-Uncensored-Erotica-NSFW** | 13B              | NSFW ì „ë¬¸ íŠœë‹ ëª¨ë¸                                        |
| 11 | **Llama-3.2-uncensored-erotica / unsloth.F16**    | 8â€“13B            | Llama 3.2 ê¸°ë°˜ ì–¸ì„¼ì„œë“œ ë²„ì „                                 |
| 12 | **Llama-3.1-405B-Instruct (Q4â€“Q8 quant)**         | 405B (ì–‘ìí™” ë²„ì „)    | ì´ˆëŒ€í˜• ì˜¤í”„ë¼ì¸ ëª¨ë¸ (LM Studio, Koboldcpp ì§€ì›)                |
| 13 | **NousResearch / Hermes-3-Llama-3.1-405B**        | 405B             | Roleplay í’ˆì§ˆ ìš°ìˆ˜, Llama3 ê¸°ë°˜                            |
| 14 | **Goliath 120B**                                  | 120B             | ê³ ì„±ëŠ¥ êµ¬í˜• ëŒ€í˜• ëª¨ë¸                                         |
| 15 | **Mistral Small**                                 | 7B               | â€œmay generate offensive materialâ€, ë‚®ì€ ê²€ì—´             |
| 16 | **Euryel / Euryale (êµ¬ë²„ì „)**                        | 30â€“70B           | Euryale ì´ˆê¸° ë²„ì „, ì¼ë¶€ QLoRA ì–‘ìí™” ì¡´ì¬                       |

> ì•ˆì „ ë©”ëª¨: NSFW/Roleplay ì‚¬ìš© ì‹œ í•­ìƒ ì„±ì¸ì„ ì „ì œë¡œ í•˜ê³ , í˜„ì§€ ë²•/í”Œë«í¼ ì •ì±…ì„ ì¤€ìˆ˜í•˜ì„¸ìš”. ë¯¸ì„±ë…„, ì°©ì·¨, ë¹„ë™ì˜ ì½˜í…ì¸ ëŠ” ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.

---

## âš™ï¸ ì‹¤í–‰ í™˜ê²½ ìš”ì•½

| GPU / RAM                               | ì‹¤í–‰ ê°€ëŠ¥í•œ ëª¨ë¸                                                       |
| --------------------------------------- | --------------------------------------------------------------- |
| **RTX 3060~3070 (8â€“12 GB)**             | Stheno 3.2, Mistral 7B Small, Blue-Orchid-2x7B (Q4), Gemmasutra |
| **RTX 3090 / 4080 / 4090 (24 GB)**      | Mistral 22B (Q4), Dirty-Muse, Llama 3.2 Unsloth F16             |
| **ì„œë²„ê¸‰ (A6000, 3090Ã—2, 64 GB RAM ì´ìƒ)**   | Euryale 2.2, Midnight Miqu 103B, Magnum 123B                    |
| **128 GB RAM + CPU inference (no GPU)** | Llama 3.1 405B Q4_K_M via LM Studio or koboldcpp                |

---

## ğŸ“¦ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜ (Hugging Face)

| ëª¨ë¸ëª…                                   | Hugging Face Repo                                                                                   |
| ------------------------------------- | --------------------------------------------------------------------------------------------------- |
| Blue-Orchid-2x7B                      | [nakodanei/Blue-Orchid-2x7b](https://huggingface.co/nakodanei/Blue-Orchid-2x7b)                     |
| Llama-3.1-405B-Instruct               | [meta-llama/Llama-3.1-405B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct)     |
| Hermes-3-Llama-3.1-405B               | [NousResearch/Hermes-3-Llama-3.1-405B](https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-405B) |
| Dirty-Muse-Writer-v01                 | [Dirty-Muse-Writer-v01-Uncensored-Erotica-NSFW](https://huggingface.co/models) (ê²€ìƒ‰ í•„ìš”)              |
| Llama-3.2-uncensored-erotica          | ê²€ìƒ‰ì–´: `Llama-3.2-uncensored-erotica unsloth`                                                         |
| Stheno 3.2 / Gemmasutra / Magnum 123B | [huggingface.co/models](https://huggingface.co/models)ì—ì„œ ì§ì ‘ ê²€ìƒ‰                                      |


## íŒŒì¼ êµ¬ì¡°
```text
output/
  positive.txt   # ë¼ì¸ë‹¹ 1ê°œ ê¸ì • í”„ë¡¬í”„íŠ¸
  negative.txt   # ê¸°ë³¸ ìƒ˜í”Œ 1ë¼ì¸
scripts/
  generate_prompts.py
```

## ë™ì‘ ê°œìš”
- `scripts/generate_prompts.py` ì‹¤í–‰ ì‹œ ê¸°ë³¸ ìƒ˜í”Œ ê¸ì •/ë¶€ì • í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- `--llm` ì‚¬ìš© ì‹œ ì‹œë“œ(ì§ì ‘ ì…ë ¥/íŒŒì¼/ê¸°ì¡´ positive.txt)ë¡œë¶€í„° ìœ ì‚¬ ê¸ì • í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ `positive.txt` ëì— ì¶”ê°€í•©ë‹ˆë‹¤.
- ì•ˆì „ ê¸°ë³¸ê°’ìœ¼ë¡œ `1girl`/`girl` ë“± ëª¨í˜¸í•œ í‘œí˜„ì€ `1woman`/`woman`ìœ¼ë¡œ ì¹˜í™˜ë©ë‹ˆë‹¤. ì›ë¬¸ ìœ ì§€ê°€ í•„ìš”í•˜ë©´ `--no-safe-adult-tags`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## ì£¼ì˜ ë° íŒ
- Ollama ëª¨ë¸ì€ ì‚¬ì „ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤(`ollama pull <ëª¨ë¸ëª…>`).
- LLM ì¶œë ¥ì´ ì—¬ëŸ¬ ì¤„/ì„¤ëª…í˜•ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš°ê°€ ë“œë¬¼ê²Œ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ê°€ 1ì¤„ë§Œ ì·¨í•˜ë„ë¡ í›„ì²˜ë¦¬í•˜ì§€ë§Œ, í•„ìš”í•˜ë©´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë” ì—„ê²©í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- Qwen(non-instruct) ëª¨ë¸ì€ `generate` ëª¨ë“œì—ì„œ ë¹ˆ ì‘ë‹µì´ ë‚˜ì˜¬ ìˆ˜ ìˆì–´ ChatML í´ë°±ì„ ìë™ ì‹œë„í•©ë‹ˆë‹¤. í•„ìš” ì‹œ `--llm-mode chat` ë˜ëŠ” `--no-qwen-chatml-fallback`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ì¤‘ë³µ ì¤„ì´ ìƒê¸°ë©´ ê°„ë‹¨íˆ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
  - `awk '!seen[$0]++' output/positive.txt > output/positive.tmp && mv output/positive.tmp output/positive.txt`


## ë¼ì´ì„ ìŠ¤
ë‚´ë¶€/ì—°êµ¬ìš©ìœ¼ë¡œ ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì„¸ìš”. ë³„ë„ ë¼ì´ì„ ìŠ¤ê°€ í•„ìš”í•˜ë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”.

## ComfyUI í…Œí¬ë‹ˆì»¬ ê°€ì´ë“œ

ë³¸ ë„êµ¬ê°€ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ComfyUIë¡œ ì „ë‹¬Â·ìë™í™”í•˜ëŠ” ë‹¤ì–‘í•œ ì‹¤ì „ ë°©ë²•ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ComfyUIëŠ” í•œ ì¤„ ê°•ì œê°€ ì•„ë‹ˆë¯€ë¡œ, íƒœê·¸ + ì‹œë‚˜ë¦¬ì˜¤ ë¬¸ì¥(ë Œì¦ˆ/ì¹´ë©”ë¼/ì¡°ëª…)ì„ ì ì ˆíˆ ì„ì€ ë©€í‹°ë¼ì¸ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ ì›Œí¬í”Œë¡œ ê°œìš”(SDXL ì˜ˆ)
- Checkpoint Loader (SDXL) â†’ ëª¨ë¸/CLIP/VAE ë¡œë“œ
- CLIP Text Encode (SDXL) Ã—2 â†’ ê¸ì •/ë¶€ì • í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”©
- Empty Latent Image â†’ í•´ìƒë„ ì§€ì •(ì˜ˆ: 1024Ã—1024)
- KSampler (SDXL) â†’ sampler/steps/cfg/seed ì œì–´
- VAE Decode â†’ Save Image

ì»·(ì‹œí€€ìŠ¤) ìš´ìš© íŒ(3â€“10ì»·)
- ìˆ˜ë™: ì»· íŒŒì¼ë³„ë¡œ í”„ë¡¬í”„íŠ¸ êµì²´ í›„ ìˆœì°¨ ì‹¤í–‰
- ë°°ì¹˜: ì»¤ë®¤ë‹ˆí‹° ë…¸ë“œ(ComfyUI-Managerë¡œ â€˜textâ€™/â€˜loopâ€™ ê²€ìƒ‰)ë¡œ íŒŒì¼â†’ë°˜ë³µ ì‹¤í–‰ êµ¬ì„±

ì¼ê´€ì„±(Continuity)
- ê³µí†µ ì‹œë“œ/ì¹´ë©”ë¼/ë Œì¦ˆ/ì¡°ëª…ì„ ì»· ì „ë°˜ì— ìœ ì§€
- IP-Adapterë¡œ ìŠ¤íƒ€ì¼ ê³ ì •, ControlNet(Depth/Lineart/SoftEdge)ë¡œ êµ¬ë„ ìœ ì§€
- SDXL Refiner(denoise 0.2â€“0.4), ESRGAN ì—…ìŠ¤ì¼€ì¼ë¡œ í’ˆì§ˆ ë³´ê°•

â€”

# 1) ComfyUI HTTP APIë¡œ â€œí…œí”Œë¦¿ ì›Œí¬í”Œë¡œìš°â€ ì¬ì „ì†¡ (ê°€ì¥ ë‹¨ìˆœ/í™•ì‹¤)

ComfyUIì˜ `/prompt` íëŠ” ìƒíƒœë¥¼ ê¸°ì–µí•˜ì§€ ì•Šì•„ì„œ ë§¤ ì‹¤í–‰ë§ˆë‹¤ ê·¸ë˜í”„(JSON)ë¥¼ ë³´ë‚´ëŠ” ê²Œ ì •ì„ì…ë‹ˆë‹¤. í…œí”Œë¦¿ workflow.jsonì„ ì €ì¥í•´ë‘ê³ , ê·¸ ì•ˆì˜ CLIPTextEncode(ì–‘ì˜ í”„ë¡¬í”„íŠ¸) ë…¸ë“œì˜ `text`ë§Œ êµì²´í•´ì„œ POST í•˜ë©´ ë©ë‹ˆë‹¤.

### 1-A. í…œí”Œë¦¿ ì¤€ë¹„

- ComfyUIì—ì„œ í˜„ì¬ ì›Œí¬í”Œë¡œìš° Export â†’ `workflow.template.json` ì €ì¥
- í¬ì§€í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ìœ„ì¹˜(ë³´í†µ `CLIPTextEncode`ì˜ `inputs.text`)ì— í† í° ë„£ê¸°: `"text": "__POS__"`

### 1-B. ì‹¤í–‰ìš© JSON ë§Œë“¤ê³  íì— ë„£ê¸° (sed + curl)

```bash
# í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ë§Œ ë°”ê¿”ì„œ ë³´ë‚¼ JSON ìƒì„±
POS="cinematic portrait, korean actress, soft light, 50mm"
sed "s|__POS__|${POS//|/\|}|g" workflow.template.json > payload.json

# ComfyUI í”„ë¡¬í”„íŠ¸ íì— ì „ì†¡ (ê¸°ë³¸ í¬íŠ¸ 8188)
curl -s -X POST http://127.0.0.1:8188/prompt \
  -H 'Content-Type: application/json' \
  -d @payload.json | jq .
```

íŒ: ComfyUIëŠ” `client_id` ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤. í…œí”Œë¦¿ ë£¨íŠ¸ì— `"client_id": "innofree-cli"` ê°™ì€ í•„ë“œë¥¼ ì¶”ê°€í•˜ë©´ íŠ¸ë˜í‚¹ì´ í¸í•©ë‹ˆë‹¤.

### 1-C. Python(ë‹¨ì¼ ìŠ¤í¬ë¦½íŠ¸)ë¡œ êµì²´Â·ì „ì†¡

```python
#!/usr/bin/env python3
import json, requests

tmpl = json.load(open("workflow.template.json"))
pos = "cinematic portrait, korean actress, soft light, 50mm"

def replace(obj):
    if isinstance(obj, dict):
        for k,v in obj.items():
            if k == "text" and isinstance(v, str) and v == "__POS__":
                obj[k] = pos
            else:
                replace(v)
    elif isinstance(obj, list):
        for i in obj:
            replace(i)

replace(tmpl)
tmpl.setdefault("client_id","innofree-cli")
r = requests.post("http://127.0.0.1:8188/prompt", json=tmpl, timeout=60)
print(r.status_code, r.text[:300])
```

â€”

# 2) â€œíŒŒì¼ ë¡œë” ë…¸ë“œâ€ + íŒŒì¼ ë®ì–´ì“°ê¸° (ê·¸ë˜í”„ëŠ” ê³ ì •, ë¬¸ìì—´ë§Œ êµì²´)

ê·¸ë˜í”„ë¥¼ ë§¤ë²ˆ ì•ˆ ë³´ë‚´ë ¤ë©´ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ëŠ” ë…¸ë“œ(ì˜ˆ: `Load Text From File`)ë¥¼ CLIPTextEncode ì•ì— ë‘ê³ , ì‹¤í–‰ ì „ë§ˆë‹¤ íŒŒì¼ë§Œ ê°±ì‹ í•©ë‹ˆë‹¤.

íë¦„
1. ì›Œí¬í”Œë¡œìš°: `Text From File` â†’ `CLIPTextEncode`
2. í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ: `/data/prompts/positive.txt`
3. ì‹¤í–‰ ì „ êµì²´:

```bash
cat > /data/prompts/positive.txt <<'EOF'
cinematic portrait, korean actress, soft light, 50mm
EOF
# ComfyUI UIì—ì„œ Run or Queue íŠ¸ë¦¬ê±° (ë˜ëŠ” APIë¡œ íŠ¸ë¦¬ê±° ë…¸ë“œ í˜¸ì¶œ)
```

ì¥ë‹¨ì 
- ì¥ì : ëŒ€ìš©ëŸ‰ ê·¸ë˜í”„ë¥¼ ë§¤ë²ˆ ì•ˆ ë³´ë‚´ë„ ë¨
- ë‹¨ì : í•´ë‹¹ ì»¤ìŠ¤í…€ ë…¸ë“œ ì„¤ì¹˜ í•„ìš”, íŠ¸ë¦¬ê±°ëŠ” ë³„ë„

â€”

# 3) MCP(Model Context Protocol) ë¸Œë¦¿ì§€ë¡œ â€œí”„ë¡¬í”„íŠ¸-ì£¼ì… íˆ´â€ ë§Œë“¤ê¸° (LLMÂ·ì—ì´ì „íŠ¸ ì—°ê²°)

MCP ì„œë²„(íŒŒì´ì¬/ë…¸ë“œ)ì—ì„œ â€œComfyUIë¡œ ì´ë¯¸ì§€ ìƒì„±â€ íˆ´ì„ ë…¸ì¶œí•˜ê³ , ë‚´ë¶€ì ìœ¼ë¡œ í…œí”Œë¦¿ JSONì˜ `__POS__` ì¹˜í™˜ â†’ `/prompt` POSTë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ChatGPT/ì—ë””í„° MCP í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë„êµ¬ í˜¸ì¶œë§Œìœ¼ë¡œ ComfyUI íŒŒì´í”„ë¼ì¸ì„ ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 3-A. Node(TypeScript) ë¯¸ë‹ˆ ì„œë²„ ì˜ˆì‹œ

```ts
// mcp-comfy.ts
import { Server } from "@modelcontextprotocol/sdk/server/mcp";
import axios from "axios";
import fs from "fs";

const server = new Server({
  name: "comfyui-bridge",
  version: "0.1.0",
  tools: [
    {
      name: "comfy_generate",
      description: "Send a positive prompt to ComfyUI using a workflow template.",
      inputSchema: {
        type: "object",
        properties: { positive: { type: "string" } },
        required: ["positive"],
      },
      handler: async ({ positive }) => {
        const tmpl = JSON.parse(fs.readFileSync("workflow.template.json","utf8"));
        const replace = (o:any) => {
          if (Array.isArray(o)) o.forEach(replace);
          else if (o && typeof o === "object") {
            for (const k of Object.keys(o)) {
              if (k === "text" && o[k] === "__POS__") o[k] = positive;
              else replace(o[k]);
            }
          }
        };
        replace(tmpl);
        tmpl.client_id = tmpl.client_id ?? "innofree-mcp";
        const { data } = await axios.post("http://127.0.0.1:8188/prompt", tmpl, { timeout: 60000 });
        return { content: [{ type: "text", text: JSON.stringify(data).slice(0,500) }] };
      },
    },
  ],
});

server.start();
```

ì„¤ì¹˜ ê°œìš”

```bash
npm i @modelcontextprotocol/sdk axios
ts-node mcp-comfy.ts # ë˜ëŠ” ë¹Œë“œ í›„ node ì‹¤í–‰
```

MCP í´ë¼ì´ì–¸íŠ¸(ì—ë””í„°Â·LLM)ê°€ ì´ ì„œë²„ë¥¼ ë“±ë¡í•˜ë©´, `comfy_generate` íˆ´ í˜¸ì¶œ ì‹œ `positive`ë§Œ ë„˜ê²¨ ComfyUIë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

### 3-B. Python MCP ì„œë²„ë„ ìœ ì‚¬í•˜ê²Œ ê°€ëŠ¥
- `modelcontextprotocol` íŒŒì´ì¬ SDK ì‚¬ìš©
- ë¡œì§ ë™ì¼: í…œí”Œë¦¿ ë¡œë“œ â†’ `__POS__` ì¹˜í™˜ â†’ `/prompt` POST

â€”

## ì–´ë–¤ ë°©ë²•ì„ ì“°ë©´ ì¢‹ì„ê¹Œ?

- ê°€ì¥ ê°„ë‹¨/ì•ˆì „: 1) í…œí”Œë¦¿ JSON ì¬ì „ì†¡
- ê·¸ë˜í”„ ê³ ì •, ë¬¸ìì—´ë§Œ ë°”ê¾¸ê¸°: 2) íŒŒì¼ ë¡œë” ë…¸ë“œ
- LLM/ì—ì´ì „íŠ¸ì™€ ì¼ì›í™”: 3) MCP ë¸Œë¦¿ì§€

## ê¸°íƒ€

- ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸: `__NEG__` í† í°ì„ ë„¤ê±°í‹°ë¸Œìª½ CLIPTextEncodeì— ë‘ê³  ë™ì¼ ë°©ì‹ìœ¼ë¡œ êµì²´
- Client-ID/íˆìŠ¤í† ë¦¬: `client_id` ê³ ì • ì‹œ `/history/{prompt_id}` ì¡°íšŒÂ·ë¡œê¹… ìš©ì´
- ëª¨ë¸/ë¡œë¼/ìƒ˜í”ŒëŸ¬/ìŠ¤í…: í…œí”Œë¦¿ì— `__CKPT__`, `__LORA__`, `__SAMPLER__`, `__STEPS__` í† í°ì„ ì¶”ê°€í•´ ì¼ê´„ ì¹˜í™˜
